{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPe0EOSeCqayKy4YsmNPmrW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jokefun022/Google-Drive/blob/main/Not_Important_Original_Facebook_Scraping_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TRMvvvds5Eji",
        "outputId": "f73ccc1d-2b0c-41cd-c63e-17dc109dd09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,722 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,932 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,212 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,901 kB]\n",
            "Fetched 21.0 MB in 12s (1,729 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "--2025-05-13 19:12:07--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.217.12.14, 2607:f8b0:4025:803::200e\n",
            "Connecting to dl.google.com (dl.google.com)|172.217.12.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116491424 (111M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 111.09M  25.1MB/s    in 5.4s    \n",
            "\n",
            "2025-05-13 19:12:12 (20.5 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [116491424/116491424]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 10.9 MB/127 MB of archives.\n",
            "After this operation, 433 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Get:3 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 136.0.7103.92-1 [116 MB]\n",
            "Fetched 10.9 MB in 2s (6,679 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (136.0.7103.92-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up google-chrome-stable (136.0.7103.92-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Google Chrome 136.0.7103.92 \n",
            "--2025-05-13 19:12:36--  https://chromedriver.storage.googleapis.com/134.0.6998.35/chromedriver_linux64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 172.217.0.91, 172.217.7.59, 172.217.12.27, ...\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|172.217.0.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-05-13 19:12:37 ERROR 404: Not Found.\n",
            "\n",
            "unzip:  cannot find or open chromedriver_linux64.zip, chromedriver_linux64.zip.zip or chromedriver_linux64.zip.ZIP.\n",
            "chmod: cannot access 'chromedriver': No such file or directory\n",
            "mv: cannot stat 'chromedriver': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y wget\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt install -y ./google-chrome-stable_current_amd64.deb\n",
        "\n",
        "\n",
        "\n",
        "!google-chrome --version\n",
        "\n",
        "\n",
        "\n",
        "!wget -N https://chromedriver.storage.googleapis.com/134.0.6998.35/chromedriver_linux64.zip\n",
        "!unzip chromedriver_linux64.zip\n",
        "!chmod +x chromedriver\n",
        "!mv -f chromedriver /usr/local/bin/chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceBookBot():\n",
        "    def __init__(self):\n",
        "        # Set up Chrome options for headless mode\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "        chrome_options.add_argument(\"--disable-gpu\")\n",
        "        chrome_options.add_argument(\"--no-sandbox\")\n",
        "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "        # Initialize the WebDriver\n",
        "        self.driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    def login(self, username, password):\n",
        "        \"\"\"Log in to Facebook.\"\"\"\n",
        "        self.driver.get(\"https://www.facebook.com\")\n",
        "        sleep(2)\n",
        "\n",
        "        # Enter email and password\n",
        "        email_in = self.driver.find_element(By.XPATH, '//*[@id=\"email\"]')  # Corrected XPath\n",
        "        email_in.send_keys(username)\n",
        "        password_in = self.driver.find_element(By.XPATH, '//*[@id=\"pass\"]')  # Corrected XPath\n",
        "        password_in.send_keys(password)\n",
        "\n",
        "        # Click login button\n",
        "        login_btn = self.driver.find_element(By.XPATH, '//*[@name=\"login\"]')  # Corrected XPath\n",
        "        login_btn.click()\n",
        "        sleep(2)"
      ],
      "metadata": {
        "id": "0dxzy1To9S-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceBookBot():\n",
        "    def __init__(self):\n",
        "        # Set up Chrome options for headless mode\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "        chrome_options.add_argument(\"--disable-gpu\")\n",
        "        chrome_options.add_argument(\"--no-sandbox\")\n",
        "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "        # Initialize the WebDriver\n",
        "        self.driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    def login(self, username, password):\n",
        "        \"\"\"Log in to Facebook.\"\"\"\n",
        "        self.driver.get(\"https://www.facebook.com\")\n",
        "        sleep(2)\n",
        "\n",
        "        # Enter email and password\n",
        "        email_in = self.driver.find_element(By.XPATH, '//*[@id=\"email\"]')  # Corrected XPath\n",
        "        email_in.send_keys(username)\n",
        "        password_in = self.driver.find_element(By.XPATH, '//*[@id=\"pass\"]')  # Corrected XPath\n",
        "        password_in.send_keys(password)\n",
        "\n",
        "        # Click login button\n",
        "        login_btn = self.driver.find_element(By.XPATH, '//*[@name=\"login\"]')  # Corrected XPath\n",
        "        login_btn.click()\n",
        "        sleep(2)"
      ],
      "metadata": {
        "id": "YtRwDDFJ9Vgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install selenium beautifulsoup4 requests\n",
        "\n",
        "# Import libraries\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By  # Import By for locating elements\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import random\n",
        "from time import sleep\n",
        "\n",
        "# Add your Facebook credentials here\n",
        "username = \"wahabzhob@gmail.com\"  # Replace with your Facebook email\n",
        "password = \"Haneef123@#$\"  # Replace with your Facebook password\n",
        "\n",
        "# ... (rest of the code for installing Chrome and ChromeDriver) ...\n",
        "\n",
        "# Define the FacebookBot class\n",
        "class FaceBookBot():\n",
        "    def __init__(self):\n",
        "        # Set up Chrome options for headless mode\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "        chrome_options.add_argument(\"--disable-gpu\")\n",
        "        chrome_options.add_argument(\"--no-sandbox\")\n",
        "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "        # Initialize the WebDriver\n",
        "        self.driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    def login(self, username, password):\n",
        "        \"\"\"Log in to Facebook.\"\"\"\n",
        "        self.driver.get(\"https://www.facebook.com/\")  # Change the URL to main login page\n",
        "        sleep(5)  # Increase sleep time to 5 seconds to ensure page load\n",
        "\n",
        "        # Enter email and password\n",
        "        email_in = self.driver.find_element(By.XPATH, '//*[@id=\"email\"]')  # Use 'email' as the id\n",
        "        email_in.send_keys(username)\n",
        "        password_in = self.driver.find_element(By.XPATH, '//*[@id=\"pass\"]')  # Use 'pass' as the id\n",
        "        password_in.send_keys(password)\n",
        "\n",
        "        # Click login button\n",
        "        login_btn = self.driver.find_element(By.XPATH, '//*[@name=\"login\"]')\n",
        "        login_btn.click()\n",
        "        sleep(2)\n",
        "\n",
        "    def post_likes(self, post_ID): # Corrected indentation here\n",
        "        \"\"\"Fetch people who liked a post.\"\"\"\n",
        "        limit = 200\n",
        "        REQUEST_URL = f'https://mbasic.facebook.com/ufi/reaction/profile/browser/fetch/?limit={limit}&total_count=17&ft_ent_identifier={post_ID}'\n",
        "\n",
        "        payload = {\n",
        "            'email': username,\n",
        "            'pass': password\n",
        "        }\n",
        "\n",
        "        with requests.Session() as session:\n",
        "            post = session.post('https://mbasic.facebook.com/login', data=payload)\n",
        "            r = session.get(REQUEST_URL)\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "        names = soup.find_all('h3', class_='be')\n",
        "        people_who_liked = [name.text for name in names]\n",
        "        return people_who_liked\n",
        "\n",
        "    def post_shares(self, post_ID): # Corrected indentation here\n",
        "        \"\"\"Fetch people who shared a post.\"\"\"\n",
        "        REQUEST_URL = f'https://m.facebook.com/browse/shares?id={post_ID}'\n",
        "\n",
        "        payload = {\n",
        "            'email': username,\n",
        "            'pass': password\n",
        "        }\n",
        "\n",
        "        with requests.Session() as session:\n",
        "            post = session.post('https://mbasic.facebook.com/login', data=payload)\n",
        "            r = session.get(REQUEST_URL)\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "        names = soup.find_all('span')\n",
        "        people_who_shared = [name.text for name in names]\n",
        "        return people_who_shared\n",
        "\n",
        "    def page_likes(self, page_name): # Corrected indentation here\n",
        "        \"\"\"Fetch people who liked a page.\"\"\"\n",
        "        self.login(username, password)\n",
        "\n",
        "        REQUEST_URL = f'https://www.facebook.com/{page_name}/settings/?tab=people_and_other_pages&ref=page_edit'\n",
        "        self.driver.get(REQUEST_URL)\n",
        "        sleep(2)\n",
        "\n",
        "        # Scroll to load more likes\n",
        "        for _ in range(1, 15):\n",
        "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            sleep(3)\n",
        "\n",
        "        page = self.driver.page_source\n",
        "        soup = BeautifulSoup(page, \"html.parser\")\n",
        "        names = soup.find_all('a', class_='_3cb8')\n",
        "        people_who_liked_page = [name.text for name in names]\n",
        "        return people_who_liked_page\n",
        "\n",
        "    def select_winner(self, list_A, list_B, list_C): # Corrected indentation here\n",
        "        \"\"\"Select a winner from eligible candidates.\"\"\"\n",
        "        eligible_to_win = [name for name in list_A if name in list_B and name in list_C]\n",
        "        return eligible_to_win\n",
        "\n",
        "# ... (rest of the code) ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zrNWMIPK_6-4",
        "outputId": "82f3f639-b54e-4d32-85b4-6f65e4fd6e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.32.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.4.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
            "Downloading selenium-4.32.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.32.0 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install selenium beautifulsoup4 requests\n",
        "\n",
        "# Import libraries\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By  # Import By for locating elements\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import random\n",
        "from time import sleep\n",
        "\n",
        "# Add your Facebook credentials here\n",
        "username = \"wahabzhob@gmail.com\"  # Replace with your Facebook email\n",
        "password = \"Haneef123@#$\"  # Replace with your Facebook password\n",
        "\n",
        "# Install Google Chrome\n",
        "!apt-get update\n",
        "!apt-get install -y wget\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt install -y ./google-chrome-stable_current_amd64.deb\n",
        "\n",
        "# Check the installed Chrome version\n",
        "!google-chrome --version\n",
        "\n",
        "# Set up ChromeDriver for Colab\n",
        "!apt-get install -y unzip\n",
        "\n",
        "# Download the correct version of ChromeDriver\n",
        "# Replace the URL with the correct version for your Chrome browser\n",
        "!wget -N https://chromedriver.storage.googleapis.com/134.0.6998.35/chromedriver_linux64.zip\n",
        "!unzip chromedriver_linux64.zip\n",
        "!chmod +x chromedriver\n",
        "!mv -f chromedriver /usr/local/bin/chromedriver\n",
        "\n",
        "# Define the FacebookBot class\n",
        "class FaceBookBot():\n",
        "    def __init__(self):\n",
        "        # Set up Chrome options for headless mode\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "        chrome_options.add_argument(\"--disable-gpu\")\n",
        "        chrome_options.add_argument(\"--no-sandbox\")\n",
        "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "        # Initialize the WebDriver\n",
        "        self.driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "    def login(self, username, password):\n",
        "        \"\"\"Log in to Facebook.\"\"\"\n",
        "        self.driver.get(\"https://www.facebook.com/\")  # Change the URL to main login page\n",
        "        sleep(5)  # Increase sleep time to 5 seconds to ensure page load\n",
        "\n",
        "        # Enter email and password\n",
        "        email_in = self.driver.find_element(By.XPATH, '//*[@id=\"email\"]')  # Use 'email' as the id\n",
        "        email_in.send_keys(username)\n",
        "        password_in = self.driver.find_element(By.XPATH, '//*[@id=\"pass\"]')  # Use 'pass' as the id\n",
        "        password_in.send_keys(password)\n",
        "\n",
        "        # Click login button\n",
        "        login_btn = self.driver.find_element(By.XPATH, '//*[@name=\"login\"]')\n",
        "        login_btn.click()\n",
        "        sleep(2)\n",
        "\n",
        "    def post_likes(self, post_ID):\n",
        "        \"\"\"Fetch people who liked a post.\"\"\"\n",
        "        limit = 200\n",
        "        REQUEST_URL = f'https://mbasic.facebook.com/ufi/reaction/profile/browser/fetch/?limit={limit}&total_count=17&ft_ent_identifier={post_ID}'\n",
        "\n",
        "        payload = {\n",
        "            'email': username,\n",
        "            'pass': password\n",
        "        }\n",
        "\n",
        "        with requests.Session() as session:\n",
        "            post = session.post('https://mbasic.facebook.com/login', data=payload)\n",
        "            r = session.get(REQUEST_URL)\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "        names = soup.find_all('h3', class_='be')\n",
        "        people_who_liked = [name.text for name in names]\n",
        "        return people_who_liked\n",
        "\n",
        "    def post_shares(self, post_ID):\n",
        "        \"\"\"Fetch people who shared a post.\"\"\"\n",
        "        REQUEST_URL = f'https://m.facebook.com/browse/shares?id={post_ID}'\n",
        "\n",
        "        payload = {\n",
        "            'email': username,\n",
        "            'pass': password\n",
        "        }\n",
        "\n",
        "        with requests.Session() as session:\n",
        "            post = session.post('https://mbasic.facebook.com/login', data=payload)\n",
        "            r = session.get(REQUEST_URL)\n",
        "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "        names = soup.find_all('span')\n",
        "        people_who_shared = [name.text for name in names]\n",
        "        return people_who_shared\n",
        "\n",
        "    def page_likes(self, page_name):\n",
        "        \"\"\"Fetch people who liked a page.\"\"\"\n",
        "        self.login(username, password)\n",
        "\n",
        "        REQUEST_URL = f'https://www.facebook.com/{page_name}/settings/?tab=people_and_other_pages&ref=page_edit'\n",
        "        self.driver.get(REQUEST_URL)\n",
        "        sleep(2)\n",
        "\n",
        "        # Scroll to load more likes\n",
        "        for _ in range(1, 15):\n",
        "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            sleep(3)\n",
        "\n",
        "        page = self.driver.page_source\n",
        "        soup = BeautifulSoup(page, \"html.parser\")\n",
        "        names = soup.find_all('a', class_='_3cb8')\n",
        "        people_who_liked_page = [name.text for name in names]\n",
        "        return people_who_liked_page\n",
        "\n",
        "    def select_winner(self, list_A, list_B, list_C):\n",
        "        \"\"\"Select a winner from eligible candidates.\"\"\"\n",
        "        eligible_to_win = [name for name in list_A if name in list_B and name in list_C]\n",
        "        return eligible_to_win\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the bot\n",
        "    bot = FaceBookBot()\n",
        "\n",
        "    # Replace these with actual values\n",
        "    post_ID = \"your_post_id\"  # Replace with the actual post ID\n",
        "    page_name = \"your_page_name\"  # Replace with the actual page name\n",
        "\n",
        "    # Fetch data\n",
        "    people_who_follow = bot.page_likes(page_name)\n",
        "    people_who_liked = bot.post_likes(post_ID)\n",
        "    people_who_shared = bot.post_shares(post_ID)\n",
        "\n",
        "    # Select a winner\n",
        "    eligible = bot.select_winner(people_who_liked, people_who_follow, people_who_shared)\n",
        "    if eligible:\n",
        "        winner = random.choice(eligible)\n",
        "        print(f\"The winner is: {winner}\")\n",
        "    else:\n",
        "        print(\"No eligible winners found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QswHzoi85-ty",
        "outputId": "3ac519ac-2ac8-4312-86f3-6a9bc58ce7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.32.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.4.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:2 https://dl.google.com/linux/chrome/deb stable InRelease [1,825 B]\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://dl.google.com/linux/chrome/deb stable/main amd64 Packages [1,219 B]\n",
            "Fetched 3,044 B in 1s (2,164 B/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "--2025-05-13 19:12:57--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.217.0.78, 2607:f8b0:4025:803::200e\n",
            "Connecting to dl.google.com (dl.google.com)|172.217.0.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116491424 (111M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb.1’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 111.09M  4.67MB/s    in 25s     \n",
            "\n",
            "2025-05-13 19:13:23 (4.47 MB/s) - ‘google-chrome-stable_current_amd64.deb.1’ saved [116491424/116491424]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "google-chrome-stable is already the newest version (136.0.7103.92-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Google Chrome 136.0.7103.92 \n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "--2025-05-13 19:13:29--  https://chromedriver.storage.googleapis.com/134.0.6998.35/chromedriver_linux64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 172.217.0.91, 172.217.7.59, 172.217.12.27, ...\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|172.217.0.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-05-13 19:13:29 ERROR 404: Not Found.\n",
            "\n",
            "unzip:  cannot find or open chromedriver_linux64.zip, chromedriver_linux64.zip.zip or chromedriver_linux64.zip.ZIP.\n",
            "chmod: cannot access 'chromedriver': No such file or directory\n",
            "mv: cannot stat 'chromedriver': No such file or directory\n",
            "No eligible winners found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install webdriver-manager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p9mB9AXlD8md",
        "outputId": "37f58126-16c5-4af4-f200-7f765abe628e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (2025.4.26)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, webdriver-manager\n",
            "Successfully installed python-dotenv-1.1.0 webdriver-manager-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "print(\"webdriver_manager is installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GQlypJPuEEA6",
        "outputId": "57d6a960-ce9d-4fb2-a448-561d65fd826e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "webdriver_manager is installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import csv\n",
        "\n",
        "# Your Facebook credentials\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"\n",
        "FB_PASSWORD = \"Haneef123@#$\"\n",
        "\n",
        "# URL of the Facebook post you want to scrape\n",
        "POST_URL = \"https://fb.watch/xXp02smlOc/\"\n",
        "\n",
        "# Set up Chrome options for headless browsing (no UI)\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Headless mode (no UI)\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Start WebDriver (automated browser)\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "# Go to Facebook login page\n",
        "driver.get(\"https://www.facebook.com/\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Login to Facebook\n",
        "email_input = driver.find_element(By.ID, \"email\")\n",
        "password_input = driver.find_element(By.ID, \"pass\")\n",
        "email_input.send_keys(FB_EMAIL)\n",
        "password_input.send_keys(FB_PASSWORD)\n",
        "password_input.send_keys(Keys.RETURN)\n",
        "time.sleep(5)  # Wait for login to complete\n",
        "\n",
        "# Open the Facebook post page\n",
        "driver.get(POST_URL)\n",
        "time.sleep(5)  # Wait for the page to load\n",
        "\n",
        "# Scroll to load more comments (optional, based on the number of comments)\n",
        "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "time.sleep(3)\n",
        "\n",
        "# Get the page source after scrolling (and loading dynamic content)\n",
        "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "# Find all comments on the post using their HTML class\n",
        "comments = soup.find_all(\"div\", {\"class\": \"UFICommentBody\"})  # You might need to update this class based on Facebook's structure\n",
        "\n",
        "# Store comments in a CSV file\n",
        "csv_filename = \"facebook_comments.csv\"\n",
        "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Comment\"])  # Write header\n",
        "    for comment in comments:\n",
        "        writer.writerow([comment.get_text()])  # Write each comment as a row\n",
        "\n",
        "print(f\"Comments have been saved to {csv_filename}\")\n",
        "\n",
        "# Close the browser\n",
        "driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJgvy-EHEPYu",
        "outputId": "0b651691-4906-48dd-dc0a-b0cfba997a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comments have been saved to facebook_comments.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import csv\n",
        "\n",
        "# Your Facebook credentials\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"\n",
        "FB_PASSWORD = \"Haneef123@#$\"\n",
        "\n",
        "# URL of the Facebook post you want to scrape\n",
        "POST_URL = \"https://www.facebook.com/share/p/1AEiwRDtvT/\"\n",
        "\n",
        "# Set up Chrome options for headless browsing (no UI)\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Headless mode (no UI)\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Start WebDriver (automated browser)\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "# Go to Facebook login page\n",
        "driver.get(\"https://www.facebook.com/\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Login to Facebook\n",
        "email_input = driver.find_element(By.ID, \"email\")\n",
        "password_input = driver.find_element(By.ID, \"pass\")\n",
        "email_input.send_keys(FB_EMAIL)\n",
        "password_input.send_keys(FB_PASSWORD)\n",
        "password_input.send_keys(Keys.RETURN)\n",
        "time.sleep(5)  # Wait for login to complete\n",
        "\n",
        "# Open the Facebook post page\n",
        "driver.get(POST_URL)\n",
        "time.sleep(5)  # Wait for the page to load\n",
        "\n",
        "# Scroll to load more comments (optional, based on the number of comments)\n",
        "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "time.sleep(3)\n",
        "\n",
        "# Get the page source after scrolling (and loading dynamic content)\n",
        "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "# Find all comments on the post using their HTML class\n",
        "comments = soup.find_all(\"div\", {\"class\": \"UFICommentBody\"})  # You might need to update this class based on Facebook's structure\n",
        "\n",
        "# Store comments in a CSV file\n",
        "csv_filename = \"facebook_comments.csv\"\n",
        "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Comment\"])  # Write header\n",
        "    for comment in comments:\n",
        "        writer.writerow([comment.get_text()])  # Write each comment as a row\n",
        "\n",
        "print(f\"Comments have been saved to {csv_filename}\")\n",
        "\n",
        "# Close the browser\n",
        "driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "546TGy4ODgw8",
        "outputId": "76e38690-5747-4b51-b45e-dc5688c3d3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comments have been saved to facebook_comments.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import csv\n",
        "\n",
        "# Your Facebook credentials\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"\n",
        "FB_PASSWORD = \"Haneef123@#$\"\n",
        "\n",
        "# URL of the Facebook post you want to scrape\n",
        "POST_URL = \"https://www.facebook.com/share/p/1AEiwRDtvT/\"\n",
        "\n",
        "# Set up Chrome options for headless browsing (no UI)\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Headless mode (no UI)\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Start WebDriver (automated browser)\n",
        "# Instead of providing a placeholder path, use ChromeDriverManager to find and manage the ChromeDriver executable\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "# Go to Facebook login page\n",
        "driver.get(\"https://www.facebook.com/\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Login to Facebook\n",
        "email_input = driver.find_element(By.ID, \"email\")\n",
        "password_input = driver.find_element(By.ID, \"pass\")\n",
        "email_input.send_keys(FB_EMAIL)\n",
        "password_input.send_keys(FB_PASSWORD)\n",
        "password_input.send_keys(Keys.RETURN)\n",
        "time.sleep(5)  # Wait for login to complete\n",
        "\n",
        "# Open the Facebook post page\n",
        "driver.get(POST_URL)\n",
        "time.sleep(5)  # Wait for the page to load\n",
        "\n",
        "# Scroll to load more comments (optional, based on the number of comments)\n",
        "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "time.sleep(3)\n",
        "\n",
        "# Get the page source after scrolling (and loading dynamic content)\n",
        "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "# Find all comments on the post using their HTML class\n",
        "comments = soup.find_all(\"div\", {\"class\": \"UFICommentBody\"})  # You might need to update this class based on Facebook's structure\n",
        "\n",
        "# Store comments in a CSV file\n",
        "csv_filename = \"facebook_comments.csv\"\n",
        "with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Comment\"])  # Write header\n",
        "    for comment in comments:\n",
        "        writer.writerow([comment.get_text()])  # Write each comment as a row\n",
        "\n",
        "print(f\"Comments have been saved to {csv_filename}\")\n",
        "\n",
        "# Close the browser\n",
        "driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJv90eBIP7dE",
        "outputId": "066f8f48-2138-4f48-86d1-c682df6e59a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comments have been saved to facebook_comments.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium beautifulsoup4 pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wMumKZ6eRM7z",
        "outputId": "70b06758-63f4-4e0c-cfb7-72f586fba8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.32.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.4.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Facebook credentials\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"  # Replace with your Facebook email\n",
        "FB_PASSWORD = \"Haneef123@#$\"  # Replace with your Facebook password\n",
        "\n",
        "# URL of the Facebook post to scrape\n",
        "POST_URL = \"https://www.facebook.com/share/p/1AEiwRDtvT/\"  # Replace with the actual post URL\n",
        "\n",
        "# Set up Chrome options for headless browsing\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no UI)\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Path to ChromeDriver (update this path if necessary)\n",
        "chrome_driver_path = \"/path/to/chromedriver\"  # Replace with the path to your ChromeDriver\n",
        "\n",
        "# Initialize WebDriver\n",
        "#driver = webdriver.Chrome(service=Service(chrome_driver_path), options=chrome_options)\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "# Function to log into Facebook\n",
        "def login_to_facebook():\n",
        "    driver.get(\"https://www.facebook.com/\")\n",
        "    time.sleep(2)  # Wait for the page to load\n",
        "\n",
        "    # Enter email\n",
        "    email_input = driver.find_element(By.ID, \"email\")\n",
        "    email_input.send_keys(FB_EMAIL)\n",
        "\n",
        "    # Enter password\n",
        "    password_input = driver.find_element(By.ID, \"pass\")\n",
        "    password_input.send_keys(FB_PASSWORD)\n",
        "\n",
        "    # Press Enter to log in\n",
        "    password_input.send_keys(Keys.RETURN)\n",
        "    time.sleep(5)  # Wait for login to complete\n",
        "\n",
        "# Function to scrape comments from a Facebook post\n",
        "def scrape_facebook_comments(post_url):\n",
        "    driver.get(post_url)\n",
        "    time.sleep(5)  # Wait for the page to load\n",
        "\n",
        "    # Scroll to load more comments (optional, adjust based on the number of comments)\n",
        "    for _ in range(3):  # Scroll 3 times to load more comments\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(2)\n",
        "\n",
        "    # Get the page source after scrolling\n",
        "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "    # Find all comments using their HTML class (update this based on Facebook's structure)\n",
        "    comments = soup.find_all(\"div\", {\"class\": \"x1iorvi4 x1pi30zi x1l90r2v x1swvt13\"})  # Update this class name\n",
        "\n",
        "    # Extract comment text\n",
        "    comment_list = []\n",
        "    for comment in comments:\n",
        "        comment_text = comment.get_text(strip=True)\n",
        "        if comment_text:  # Only add non-empty comments\n",
        "            comment_list.append(comment_text)\n",
        "\n",
        "    return comment_list\n",
        "\n",
        "# Main script\n",
        "try:\n",
        "    # Log into Facebook\n",
        "    login_to_facebook()\n",
        "\n",
        "    # Scrape comments from the post\n",
        "    comments = scrape_facebook_comments(POST_URL)\n",
        "\n",
        "    # Save comments to a CSV file\n",
        "    df = pd.DataFrame(comments, columns=[\"Comment\"])\n",
        "    df.to_csv(\"facebook_comments_roman_urdu.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(f\"Scraped {len(comments)} comments and saved to 'facebook_comments_roman_urdu.csv'.\")\n",
        "\n",
        "finally:\n",
        "    # Close the browser\n",
        "    driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tFR2oUARUVt",
        "outputId": "7764677d-e985-495b-de62-3a62ff8013ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 0 comments and saved to 'facebook_comments_roman_urdu.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Facebook credentials\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"  # Replace with your Facebook email\n",
        "FB_PASSWORD = \"Haneef123@#$\"  # Replace with your Facebook password\n",
        "\n",
        "# URL of the Facebook post to scrape\n",
        "POST_URL = \"https://www.facebook.com/share/p/16Any9EGtw/\"  # Replace with the actual post URL\n",
        "\n",
        "# Set up Chrome options for headless browsing\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no UI)\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Path to ChromeDriver (update this path if necessary)\n",
        "chrome_driver_path = \"/path/to/chromedriver\"  # Replace with the path to your ChromeDriver\n",
        "\n",
        "# Initialize WebDriver\n",
        "#driver = webdriver.Chrome(service=Service(chrome_driver_path), options=chrome_options)\n",
        "\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "\n",
        "# Function to log into Facebook\n",
        "def login_to_facebook():\n",
        "    driver.get(\"https://www.facebook.com/\")\n",
        "    time.sleep(2)  # Wait for the page to load\n",
        "\n",
        "    # Enter email\n",
        "    email_input = driver.find_element(By.ID, \"email\")\n",
        "    email_input.send_keys(FB_EMAIL)\n",
        "\n",
        "    # Enter password\n",
        "    password_input = driver.find_element(By.ID, \"pass\")\n",
        "    password_input.send_keys(FB_PASSWORD)\n",
        "\n",
        "    # Press Enter to log in\n",
        "    password_input.send_keys(Keys.RETURN)\n",
        "    time.sleep(5)  # Wait for login to complete\n",
        "\n",
        "# Function to scrape comments from a Facebook post\n",
        "def scrape_facebook_comments(post_url, max_comments=10):\n",
        "    driver.get(post_url)\n",
        "    time.sleep(5)  # Wait for the page to load\n",
        "\n",
        "    comment_list = []\n",
        "    scroll_attempts = 0\n",
        "    max_scroll_attempts = 20  # Maximum number of scroll attempts to avoid infinite loops\n",
        "\n",
        "    while len(comment_list) < max_comments and scroll_attempts < max_scroll_attempts:\n",
        "        # Scroll to load more comments\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(2)  # Wait for comments to load\n",
        "\n",
        "        # Get the page source after scrolling\n",
        "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "        # Find all comments using their HTML class (update this based on Facebook's structure)\n",
        "        comments = soup.find_all(\"div\", {\"class\": \"x1iorvi4 x1pi30zi x1l90r2v x1swvt13\"})  # Update this class name\n",
        "\n",
        "        # Extract comment text\n",
        "        for comment in comments:\n",
        "            comment_text = comment.get_text(strip=True)\n",
        "            if comment_text and comment_text not in comment_list:  # Avoid duplicates\n",
        "                comment_list.append(comment_text)\n",
        "\n",
        "        # Stop if we've collected enough comments\n",
        "        if len(comment_list) >= max_comments:\n",
        "            break\n",
        "\n",
        "        scroll_attempts += 1\n",
        "\n",
        "    return comment_list[:max_comments]  # Return only the required number of comments\n",
        "\n",
        "# Main script\n",
        "try:\n",
        "    # Log into Facebook\n",
        "    login_to_facebook()\n",
        "\n",
        "    # Scrape comments from the post\n",
        "    comments = scrape_facebook_comments(POST_URL, max_comments=10)\n",
        "\n",
        "    # Save comments to a CSV file\n",
        "    df = pd.DataFrame(comments, columns=[\"Comment\"])\n",
        "    df.to_csv(\"facebook_comments_roman_urdu.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(f\"Scraped {len(comments)} comments and saved to 'facebook_comments_roman_urdu.csv'.\")\n",
        "\n",
        "finally:\n",
        "    # Close the browser\n",
        "    driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpobdnggUZ9M",
        "outputId": "4750990e-34f5-41b0-ba68-58c977628999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 0 comments and saved to 'facebook_comments_roman_urdu.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Facebook credentials\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"  # Replace with your Facebook email\n",
        "FB_PASSWORD = \"Haneef123@#$\"  # Replace with your Facebook password\n",
        "\n",
        "# URL of the Facebook post to scrape\n",
        "POST_URL = \"https://www.facebook.com/share/r/1CA9ygiibm/\"  # Replace with the actual post URL\n",
        "\n",
        "# Set up Chrome options for headless browsing\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no UI)\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Initialize WebDriver using webdriver_manager\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "# Function to log into Facebook\n",
        "def login_to_facebook():\n",
        "    try:\n",
        "        driver.get(\"https://www.facebook.com/\")\n",
        "        time.sleep(2)  # Wait for the page to load\n",
        "\n",
        "        # Enter email\n",
        "        email_input = driver.find_element(By.ID, \"email\")\n",
        "        email_input.send_keys(FB_EMAIL)\n",
        "\n",
        "        # Enter password\n",
        "        password_input = driver.find_element(By.ID, \"pass\")\n",
        "        password_input.send_keys(FB_PASSWORD)\n",
        "\n",
        "        # Press Enter to log in\n",
        "        password_input.send_keys(Keys.RETURN)\n",
        "        time.sleep(5)  # Wait for login to complete\n",
        "    except Exception as e:\n",
        "        print(f\"Error during login: {e}\")\n",
        "        driver.quit()\n",
        "        exit()\n",
        "\n",
        "# Function to scrape comments from a Facebook post\n",
        "def scrape_facebook_comments(post_url, max_comments=1000):\n",
        "    try:\n",
        "        driver.get(post_url)\n",
        "        time.sleep(5)  # Wait for the page to load\n",
        "\n",
        "        comment_list = []\n",
        "        scroll_attempts = 0\n",
        "        max_scroll_attempts = 20  # Maximum number of scroll attempts to avoid infinite loops\n",
        "\n",
        "        while len(comment_list) < max_comments and scroll_attempts < max_scroll_attempts:\n",
        "            # Scroll to load more comments\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(2)  # Wait for comments to load\n",
        "\n",
        "            # Get the page source after scrolling\n",
        "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "            # Find all comments using their HTML class (update this based on Facebook's structure)\n",
        "            comments = soup.find_all(\"div\", {\"class\": \"x1iorvi4 x1pi30zi x1l90r2v x1swvt13\"})  # Update this class name\n",
        "\n",
        "            # Extract comment text\n",
        "            for comment in comments:\n",
        "                comment_text = comment.get_text(strip=True)\n",
        "                if comment_text and comment_text not in comment_list:  # Avoid duplicates\n",
        "                    comment_list.append(comment_text)\n",
        "\n",
        "            # Stop if we've collected enough comments\n",
        "            if len(comment_list) >= max_comments:\n",
        "                break\n",
        "\n",
        "            scroll_attempts += 1\n",
        "\n",
        "        return comment_list[:max_comments]  # Return only the required number of comments\n",
        "    except Exception as e:\n",
        "        print(f\"Error during comment scraping: {e}\")\n",
        "        return []\n",
        "\n",
        "# Main script\n",
        "try:\n",
        "    # Log into Facebook\n",
        "    login_to_facebook()\n",
        "\n",
        "    # Scrape comments from the post\n",
        "    comments = scrape_facebook_comments(POST_URL, max_comments=1000)\n",
        "\n",
        "    # Save comments to a CSV file\n",
        "    if comments:\n",
        "        df = pd.DataFrame(comments, columns=[\"Comment\"])\n",
        "        df.to_csv(\"facebook_comments_roman_urdu.csv\", index=False, encoding=\"utf-8\")\n",
        "        print(f\"Scraped {len(comments)} comments and saved to 'facebook_comments_roman_urdu.csv'.\")\n",
        "    else:\n",
        "        print(\"No comments were scraped.\")\n",
        "\n",
        "finally:\n",
        "    # Close the browser\n",
        "    driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSxDTcmocJNG",
        "outputId": "7d4cb504-f2e3-4ca4-ca0d-044179b1f014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No comments were scraped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Facebook credentials\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"\n",
        "FB_PASSWORD = \"Haneef123@#$\"\n",
        "\n",
        "# URL of the Facebook post to scrape\n",
        "POST_URL = \"https://www.facebook.com/share/r/1CA9ygiibm/\"\n",
        "\n",
        "# Set up Chrome options (disable headless mode for debugging)\n",
        "chrome_options = Options()\n",
        "# chrome_options.add_argument(\"--headless\")  # Disabled for debugging\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# Initialize WebDriver\n",
        "#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "\n",
        "#driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "def login_to_facebook():\n",
        "    try:\n",
        "        driver.get(\"https://www.facebook.com/\")\n",
        "        time.sleep(3)\n",
        "\n",
        "        # Handle cookies popup (if any)\n",
        "        try:\n",
        "            accept_button = driver.find_element(By.XPATH, \"//button[contains(text(), 'Allow essential and optional cookies')]\")\n",
        "            accept_button.click()\n",
        "            time.sleep(2)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Login\n",
        "        email_input = driver.find_element(By.ID, \"email\")\n",
        "        email_input.send_keys(FB_EMAIL)\n",
        "        password_input = driver.find_element(By.ID, \"pass\")\n",
        "        password_input.send_keys(FB_PASSWORD)\n",
        "        password_input.send_keys(Keys.RETURN)\n",
        "        time.sleep(8)  # Wait for login to complete\n",
        "    except Exception as e:\n",
        "        print(f\"Login failed: {e}\")\n",
        "        driver.quit()\n",
        "        exit()\n",
        "\n",
        "def scrape_facebook_comments(post_url, max_comments=100):\n",
        "    try:\n",
        "        driver.get(post_url)\n",
        "        time.sleep(10)  # Wait longer for post to load\n",
        "\n",
        "        comment_list = []\n",
        "        scroll_attempts = 0\n",
        "\n",
        "        while len(comment_list) < max_comments and scroll_attempts < 30:\n",
        "            # Scroll to load comments\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(3)  # Increased delay for comments to load\n",
        "\n",
        "            # Parse comments\n",
        "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "            # Updated class for comments (verify via browser inspection)\n",
        "            comments = soup.find_all(\"div\", {\n",
        "                \"class\": \"x1y1aw1k xwib8y2 x1swvt13 x1pi30zi\"  # Update this!\n",
        "            })\n",
        "\n",
        "            # Extract text\n",
        "            for comment in comments:\n",
        "                text = comment.get_text(strip=True)\n",
        "                if text and text not in comment_list:\n",
        "                    comment_list.append(text)\n",
        "\n",
        "            # Break if enough comments\n",
        "            if len(comment_list) >= max_comments:\n",
        "                break\n",
        "\n",
        "            scroll_attempts += 1\n",
        "\n",
        "        return comment_list[:max_comments]\n",
        "    except Exception as e:\n",
        "        print(f\"Scraping error: {e}\")\n",
        "        return []\n",
        "\n",
        "try:\n",
        "    login_to_facebook()\n",
        "    comments = scrape_facebook_comments(POST_URL, max_comments=100)\n",
        "\n",
        "    if comments:\n",
        "        df = pd.DataFrame(comments, columns=[\"Comment\"])\n",
        "        df.to_csv(\"facebook_comments_roman_urdu.csv\", index=False, encoding=\"utf-8\")\n",
        "        print(f\"Success! Saved {len(comments)} comments.\")\n",
        "    else:\n",
        "        print(\"No comments found.\")\n",
        "\n",
        "finally:\n",
        "    driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kiWpDJZdywjW",
        "outputId": "d2abc48f-1013-45d8-8d43-a355237a658c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9ef1750>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104/url\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9ef22d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104/url\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9ef31d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104/url\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9ef8dd0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9ef9650>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9efa150>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9efbfd0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104/url\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9f10f90>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104/url\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9f11ed0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104/url\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9efa9d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9ef9190>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9ef83d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/7469fa486dc8d5d6aff6faac91d39104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login failed: HTTPConnectionPool(host='localhost', port=57027): Max retries exceeded with url: /session/7469fa486dc8d5d6aff6faac91d39104/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9ef80d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "Scraping error: HTTPConnectionPool(host='localhost', port=57027): Max retries exceeded with url: /session/7469fa486dc8d5d6aff6faac91d39104/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x78f8d9efb450>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "No comments found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Facebook credentials\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"\n",
        "FB_PASSWORD = \"Haneef123@#$\"\n",
        "\n",
        "# URL of the Facebook post to scrape\n",
        "POST_URL = \"https://www.facebook.com/share/p/16Any9EGtw/\"\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# Initialize WebDriver properly\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# Open Facebook login page\n",
        "driver.get(\"https://www.facebook.com/login\")\n",
        "\n",
        "# Wait for elements to load\n",
        "time.sleep(3)\n",
        "\n",
        "# ✅ Find email input field correctly\n",
        "email_field = driver.find_element(By.ID, \"email\")\n",
        "email_field.send_keys(FB_EMAIL)\n",
        "\n",
        "# ✅ Find password input field correctly\n",
        "password_field = driver.find_element(By.ID, \"pass\")\n",
        "password_field.send_keys(FB_PASSWORD)\n",
        "\n",
        "# ✅ Press login button\n",
        "password_field.send_keys(Keys.RETURN)\n",
        "\n",
        "# Wait for login to complete\n",
        "time.sleep(5)\n",
        "\n",
        "# Navigate to the post URL\n",
        "driver.get(POST_URL)\n",
        "\n",
        "# Wait for the post to load\n",
        "time.sleep(5)\n",
        "\n",
        "# Get page source and parse with BeautifulSoup\n",
        "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "# ✅ Initialize post_content properly\n",
        "post_content = \"\"\n",
        "\n",
        "# ✅ Try a more generic class name for Facebook posts\n",
        "post_content_element = soup.find(\"div\", {\"dir\": \"auto\"})\n",
        "\n",
        "if post_content_element:\n",
        "    post_content = post_content_element.text\n",
        "    print(\"Post Content:\", post_content)\n",
        "else:\n",
        "    print(\"❌ Post content element not found.\")\n",
        "\n",
        "# Close the browser\n",
        "driver.quit()\n"
      ],
      "metadata": {
        "id": "xmJMHYvEsE7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a4a91c-a98d-4db2-aaa6-542908534a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Post content element not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Facebook credentials (USE APP PASSWORD FOR SECURITY)\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"\n",
        "FB_PASSWORD = \"Haneef123@#$\"\n",
        "\n",
        "# Facebook post URL\n",
        "POST_URL = \"https://www.facebook.com/share/p/16Any9EGtw/\"\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# Initialize WebDriver\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# Open Facebook login page\n",
        "driver.get(\"https://www.facebook.com/login\")\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "# Login process\n",
        "email_field = driver.find_element(By.ID, \"email\")\n",
        "email_field.send_keys(FB_EMAIL)\n",
        "\n",
        "password_field = driver.find_element(By.ID, \"pass\")\n",
        "password_field.send_keys(FB_PASSWORD)\n",
        "password_field.send_keys(Keys.RETURN)\n",
        "\n",
        "time.sleep(5)  # Wait for login\n",
        "\n",
        "# Navigate to the post\n",
        "driver.get(POST_URL)\n",
        "time.sleep(5)\n",
        "\n",
        "# Scroll to load comments\n",
        "for _ in range(5):  # Scroll multiple times to load more comments\n",
        "    driver.execute_script(\"window.scrollBy(0, 500);\")\n",
        "    time.sleep(2)\n",
        "\n",
        "# Get page source after scrolling\n",
        "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "# Extract post content\n",
        "post_content = \"\"\n",
        "post_content_element = soup.find(\"div\", {\"dir\": \"auto\"})\n",
        "if post_content_element:\n",
        "    post_content = post_content_element.text\n",
        "print(\"📌 Post Content:\", post_content)\n",
        "\n",
        "# Extract comments\n",
        "comments = []\n",
        "comment_elements = soup.find_all(\"div\", {\"dir\": \"auto\"})  # Facebook uses 'dir=\"auto\"' for text elements\n",
        "\n",
        "for comment in comment_elements:\n",
        "    comment_text = comment.get_text(strip=True)\n",
        "    if comment_text and comment_text != post_content:  # Avoid extracting the post itself\n",
        "        comments.append(comment_text)\n",
        "\n",
        "# Print comments\n",
        "print(\"\\n💬 Extracted Comments:\")\n",
        "for idx, comment in enumerate(comments, start=1):\n",
        "    print(f\"{idx}. {comment}\")\n",
        "\n",
        "# Save comments to a CSV file\n",
        "df = pd.DataFrame(comments, columns=[\"Comment\"])\n",
        "df.to_csv(\"facebook_comments.csv\", index=False)\n",
        "print(\"\\n✅ Comments saved to 'facebook_comments.csv'\")\n",
        "\n",
        "# Close the browser\n",
        "driver.quit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUFFRpGsH9cj",
        "outputId": "a5199b33-d94f-41a7-8039-c0ae50728b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Post Content: \n",
            "\n",
            "💬 Extracted Comments:\n",
            "\n",
            "✅ Comments saved to 'facebook_comments.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "chrome_driver_path = ChromeDriverManager().install()\n",
        "print(f\"ChromeDriver installed at: {chrome_driver_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOsrGrc0J9g2",
        "outputId": "bd2fda82-8dd4-488b-9cca-1bbbc8518347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChromeDriver installed at: /root/.wdm/drivers/chromedriver/linux64/136.0.7103.92/chromedriver-linux64/chromedriver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--disable-gpu\")"
      ],
      "metadata": {
        "id": "Ijfr48cfJ7pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chrome_options.add_argument(\"--incognito\")"
      ],
      "metadata": {
        "id": "ystfZsQAJ3FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "# Create a unique temp directory for user data\n",
        "user_data_dir = tempfile.mkdtemp()\n",
        "chrome_options.add_argument(f\"--user-data-dir={user_data_dir}\")"
      ],
      "metadata": {
        "id": "hf5e3i17KxSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Facebook credentials (USE APP PASSWORD FOR SECURITY)\n",
        "FB_EMAIL = \"wahabzhob@gmail.com\"\n",
        "FB_PASSWORD = \"Haneef123@#$\"\n",
        "\n",
        "# Facebook post URL\n",
        "POST_URL = \"https://www.facebook.com/share/p/16Any9EGtw/\"\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# Initialize WebDriver\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# Open Facebook login page\n",
        "driver.get(\"https://www.facebook.com/login\")\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "# Login process\n",
        "email_field = driver.find_element(By.ID, \"email\")\n",
        "email_field.send_keys(FB_EMAIL)\n",
        "\n",
        "password_field = driver.find_element(By.ID, \"pass\")\n",
        "password_field.send_keys(FB_PASSWORD)\n",
        "password_field.send_keys(Keys.RETURN)\n",
        "\n",
        "time.sleep(5)  # Wait for login\n",
        "\n",
        "\n",
        "# ✅ Kill any running Chrome processes to prevent conflicts\n",
        "try:\n",
        "    os.system(\"pkill -f chrome\")  # For Linux/macOS\n",
        "    os.system(\"taskkill /F /IM chrome.exe /T\")  # For Windows (may need Admin rights)\n",
        "except:\n",
        "    pass  # Ignore errors if Chrome isn't running\n",
        "\n",
        "# ✅ Set up Chrome options (DO NOT use --user-data-dir)\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# Optional (for debugging)\n",
        "# chrome_options.add_argument(\"--headless\")  # Enable headless mode if needed\n",
        "# chrome_options.add_argument(\"--incognito\")\n",
        "\n",
        "# ✅ Ensure latest ChromeDriver version\n",
        "service = Service(ChromeDriverManager().install())\n",
        "\n",
        "\n",
        "# Pause for manual login (if needed)\n",
        "time.sleep(5)\n",
        "\n",
        "# Continue with your scraping logic...\n"
      ],
      "metadata": {
        "id": "FfstibUVMUno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# ✅ Kill any running Chrome processes to prevent conflicts\n",
        "try:\n",
        "    os.system(\"pkill -f chrome\")  # For Linux/macOS\n",
        "    os.system(\"taskkill /F /IM chrome.exe /T\")  # For Windows (may need Admin rights)\n",
        "except:\n",
        "    pass  # Ignore errors if Chrome isn't running\n",
        "\n",
        "# ✅ Set up Chrome options (DO NOT use --user-data-dir)\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# Optional (for debugging)\n",
        "# chrome_options.add_argument(\"--headless\")  # Enable headless mode if needed\n",
        "# chrome_options.add_argument(\"--incognito\")\n",
        "\n",
        "# ✅ Ensure latest ChromeDriver version\n",
        "service = Service(ChromeDriverManager().install())\n",
        "\n",
        "# ✅ Initialize WebDriver\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# ✅ Open Facebook login page\n",
        "driver.get(\"https://www.facebook.com\")\n",
        "\n",
        "# Pause for manual login (if needed)\n",
        "time.sleep(5)\n",
        "\n",
        "# Continue with your scraping logic...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "VPwsB4YdL5yx",
        "outputId": "8d4eff22-acf7-4978-90e7-753a08c0295d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SessionNotCreatedException",
          "evalue": "Message: session not created: probably user data directory is already in use, please specify a unique value for --user-data-dir argument, or don't use --user-data-dir\nStacktrace:\n#0 0x582b0b70678a <unknown>\n#1 0x582b0b1a90a0 <unknown>\n#2 0x582b0b1e31ff <unknown>\n#3 0x582b0b1dec0f <unknown>\n#4 0x582b0b22ed75 <unknown>\n#5 0x582b0b22e296 <unknown>\n#6 0x582b0b220173 <unknown>\n#7 0x582b0b1ecd4b <unknown>\n#8 0x582b0b1ed9b1 <unknown>\n#9 0x582b0b6cb93b <unknown>\n#10 0x582b0b6cf83a <unknown>\n#11 0x582b0b6b3692 <unknown>\n#12 0x582b0b6d03c4 <unknown>\n#13 0x582b0b6984cf <unknown>\n#14 0x582b0b6f4568 <unknown>\n#15 0x582b0b6f4746 <unknown>\n#16 0x582b0b7055f6 <unknown>\n#17 0x7ce950c8cac3 <unknown>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-86e3db21c161>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# ✅ Initialize WebDriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# ✅ Open Facebook login page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mbrowser_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mvendor_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fedcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFedCM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sessionId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mSessionNotCreatedException\u001b[0m: Message: session not created: probably user data directory is already in use, please specify a unique value for --user-data-dir argument, or don't use --user-data-dir\nStacktrace:\n#0 0x582b0b70678a <unknown>\n#1 0x582b0b1a90a0 <unknown>\n#2 0x582b0b1e31ff <unknown>\n#3 0x582b0b1dec0f <unknown>\n#4 0x582b0b22ed75 <unknown>\n#5 0x582b0b22e296 <unknown>\n#6 0x582b0b220173 <unknown>\n#7 0x582b0b1ecd4b <unknown>\n#8 0x582b0b1ed9b1 <unknown>\n#9 0x582b0b6cb93b <unknown>\n#10 0x582b0b6cf83a <unknown>\n#11 0x582b0b6b3692 <unknown>\n#12 0x582b0b6d03c4 <unknown>\n#13 0x582b0b6984cf <unknown>\n#14 0x582b0b6f4568 <unknown>\n#15 0x582b0b6f4746 <unknown>\n#16 0x582b0b7055f6 <unknown>\n#17 0x7ce950c8cac3 <unknown>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# 🔹 **Fix 1: Use a fresh, unique user data directory** 🔹\n",
        "user_data_dir = tempfile.mkdtemp()  # Creates a temporary directory\n",
        "chrome_options.add_argument(f\"--user-data-dir={user_data_dir}\")\n",
        "\n",
        "# 🔹 **Fix 2: Run in incognito mode (optional)** 🔹\n",
        "chrome_options.add_argument(\"--incognito\")\n",
        "\n",
        "# 🔹 **Fix 3: Run in headless mode (optional, remove if debugging)** 🔹\n",
        "# chrome_options.add_argument(\"--headless\")\n",
        "# chrome_options.add_argument(\"--disable-gpu\")\n",
        "\n",
        "# 🔹 **Fix 4: Ensure ChromeDriver is properly installed and up-to-date** 🔹\n",
        "service = Service(ChromeDriverManager().install())\n",
        "\n",
        "# 🔹 **Fix 5: Kill any existing Chrome processes (if needed)** 🔹\n",
        "try:\n",
        "    os.system(\"pkill -f chrome\")  # For Linux/macOS\n",
        "    os.system(\"taskkill /F /IM chrome.exe /T\")  # For Windows (may need Admin rights)\n",
        "except:\n",
        "    pass  # Ignore errors if Chrome isn't running\n",
        "\n",
        "# Initialize WebDriver\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# Open Facebook login page\n",
        "driver.get(\"https://www.facebook.com\")\n",
        "\n",
        "# Add login logic here...\n",
        "\n"
      ],
      "metadata": {
        "id": "H5kqfV6bHlB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Facebook credentials (USE APP PASSWORD FOR SECURITY)\n",
        "FB_EMAIL = \"your_email@example.com\"\n",
        "FB_PASSWORD = \"your_password\"\n",
        "\n",
        "# Facebook post URL\n",
        "POST_URL = \"https://www.facebook.com/share/p/16Any9EGtw/\"\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# Initialize WebDriver\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# Open Facebook login page\n",
        "driver.get(\"https://www.facebook.com/login\")\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "# Login process\n",
        "email_field = driver.find_element(By.ID, \"email\")\n",
        "email_field.send_keys(FB_EMAIL)\n",
        "\n",
        "password_field = driver.find_element(By.ID, \"pass\")\n",
        "password_field.send_keys(FB_PASSWORD)\n",
        "password_field.send_keys(Keys.RETURN)\n",
        "\n",
        "time.sleep(5)  # Wait for login\n",
        "\n",
        "# Navigate to the post\n",
        "driver.get(POST_URL)\n",
        "time.sleep(5)\n",
        "\n",
        "# Click \"View More Comments\" button multiple times to load all comments\n",
        "for _ in range(5):  # Adjust the range for more comments\n",
        "    try:\n",
        "        more_comments_button = driver.find_element(By.XPATH, \"//div[contains(text(), 'View more comments')]\")\n",
        "        driver.execute_script(\"arguments[0].click();\", more_comments_button)\n",
        "        time.sleep(3)  # Wait for comments to load\n",
        "    except:\n",
        "        break  # No more \"View More Comments\" button\n",
        "\n",
        "# Scroll to load comments\n",
        "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "time.sleep(5)\n",
        "\n",
        "# Get page source after scrolling\n",
        "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "# Extract post content\n",
        "post_content = \"\"\n",
        "post_content_element = soup.find(\"div\", {\"dir\": \"auto\"})\n",
        "if post_content_element:\n",
        "    post_content = post_content_element.text.strip()\n",
        "print(\"📌 Post Content:\", post_content)\n",
        "\n",
        "# Extract comments using better selectors\n",
        "comments = []\n",
        "comment_elements = soup.find_all(\"div\", {\"data-ad-preview\": \"message\"})  # This targets comment text\n",
        "\n",
        "for comment in comment_elements:\n",
        "    comment_text = comment.get_text(strip=True)\n",
        "    if comment_text:\n",
        "        comments.append(comment_text)\n",
        "\n",
        "# Print extracted comments\n",
        "print(\"\\n💬 Extracted Comments:\")\n",
        "for idx, comment in enumerate(comments, start=1):\n",
        "    print(f\"{idx}. {comment}\")\n",
        "\n",
        "# Save comments to CSV file\n",
        "df = pd.DataFrame(comments, columns=[\"Comment\"])\n",
        "df.to_csv(\"facebook_comments.csv\", index=False)\n",
        "print(\"\\n✅ Comments saved to 'facebook_comments.csv'\")\n",
        "\n",
        "# Close the browser\n",
        "driver.quit()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aOVVPL-tzWKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Facebook credentials (USE APP PASSWORD FOR SECURITY)\n",
        "FB_EMAIL = \"your_email@example.com\"\n",
        "FB_PASSWORD = \"your_password\"\n",
        "\n",
        "# Facebook post URL\n",
        "POST_URL = \"https://www.facebook.com/share/p/16Any9EGtw/\"\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = Options()\n",
        "# Add a unique user data directory to avoid conflicts\n",
        "user_data_dir = os.path.abspath(\"chrome_user_data\")  # Create a unique directory\n",
        "chrome_options.add_argument(f\"--user-data-dir={user_data_dir}\")\n",
        "\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\")\n",
        "\n",
        "# Initialize WebDriver\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# ... (rest of your code remains the same) ..."
      ],
      "metadata": {
        "collapsed": true,
        "id": "FTIouItsznRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "# Facebook Login Credentials\n",
        "FB_EMAIL = \"your_email@example.com\"\n",
        "FB_PASSWORD = \"your_password\"\n",
        "\n",
        "# Facebook Post URL\n",
        "POST_URL = \"https://www.facebook.com/share/p/16Any9EGtw/\"\n",
        "\n",
        "# Chrome Options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "chrome_options.add_argument(\"--disable-infobars\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Initialize WebDriver\n",
        "service = Service(ChromeDriverManager().install())\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "# Open Facebook login page\n",
        "driver.get(\"https://www.facebook.com/login\")\n",
        "time.sleep(3)\n",
        "\n",
        "# Login to Facebook\n",
        "driver.find_element(By.ID, \"email\").send_keys(FB_EMAIL)\n",
        "driver.find_element(By.ID, \"pass\").send_keys(FB_PASSWORD, Keys.RETURN)\n",
        "time.sleep(5)\n",
        "\n",
        "# Navigate to the post\n",
        "driver.get(POST_URL)\n",
        "time.sleep(5)\n",
        "\n",
        "# Click \"View More Comments\" multiple times\n",
        "for _ in range(10):\n",
        "    try:\n",
        "        more_comments_button = driver.find_element(By.XPATH, \"//div[contains(text(), 'View more comments')]\")\n",
        "        driver.execute_script(\"arguments[0].click();\", more_comments_button)\n",
        "        time.sleep(3)\n",
        "    except:\n",
        "        break\n",
        "\n",
        "# Get page source and parse with BeautifulSoup\n",
        "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "# Extract comments\n",
        "comments = []\n",
        "for comment in soup.find_all(\"div\", {\"dir\": \"auto\"}):\n",
        "    comments.append(comment.get_text(strip=True))\n",
        "\n",
        "# Print extracted comments\n",
        "print(\"\\n💬 Extracted Comments:\")\n",
        "for idx, comment in enumerate(comments, start=1):\n",
        "    print(f\"{idx}. {comment}\")\n",
        "\n",
        "# Save to file\n",
        "with open(\"facebook_comments.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    for comment in comments:\n",
        "        file.write(comment + \"\\n\")\n",
        "\n",
        "print(\"✅ Comments saved to 'facebook_comments.txt'\")\n",
        "\n",
        "# Close browser\n",
        "driver.quit()\n"
      ],
      "metadata": {
        "id": "Ojna5toS9maI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}